name: Copy prod (secnum) DB to nightly (secnum-nightly) DB

on:
  workflow_dispatch:
  schedule:
    - cron: "03 23 * * *"

jobs:
  duplicate-prod-db-to-nightly:
    runs-on: ubuntu-latest
    name: Dump and restore the remote database data.

    steps:
      - uses: actions/checkout@v4
      - name: Install scalingo CLI
        uses: ./.github/actions/install-scalingo-cli

      - name: Login with api-token
        run: scalingo login --api-token=${{ secrets.SCALINGO_API_TOKEN_SECNUM }}

      - name: Dump the remote database data and restore it to the local database.
        run: >-
          scalingo --region osc-secnum-fr1 --app if-prod-nightly-db run --size XL -- bash -c "
                echo \"> \$(date) - Installing tools\" &&
                  install-scalingo-cli &&
                  dbclient-fetcher pgsql &&
                echo \"> \$(date) - Dumping prod DB (excluding large unused tables)\" &&
                  pg_dump --dbname=\"\$SOURCE_PROD_DATABASE_URL\" \
                    --format=custom \
                    --no-owner \
                    --no-privileges \
                    --no-comments \
                    --exclude-table=outbox \
                    --exclude-table=outbox_publications \
                    --exclude-table=outbox_failures \
                    --exclude-table=notifications_email \
                    --exclude-table=notifications_email_recipients \
                    --exclude-table=notifications_email_attachments \
                    --exclude-table=notifications_sms \
                    --exclude-table=short_links \
                    --exclude-table=spatial_ref_sys \
                    --exclude-table=searches_made \
                    --exclude-table=searches_made__appellation_code \
                    --exclude-table=searches_made__naf_code \
                    --exclude-schema=tiger \
                    --exclude-schema=tiger_data \
                    --exclude-schema=topology \
                    --exclude-schema=\"metabase*\" \
                    --file=dump.pgsql &&
                echo \"> \$(date) - Dump complete, dropping nightly data\" &&
                  psql \$SCALINGO_POSTGRESQL_URL -c 'DROP OWNED BY CURRENT_USER CASCADE;' &&
                echo \"> \$(date) - Add Postgis extension if not exists\" &&
                  psql \$SCALINGO_POSTGRESQL_URL -c 'CREATE EXTENSION IF NOT EXISTS postgis;' &&
                echo \"> \$(date) - Starting restore to nightly\" &&
                  pg_restore \
                    --dbname=\$SCALINGO_POSTGRESQL_URL \
                    --jobs=8 \
                    --verbose \
                    --no-owner \
                    --no-privileges \
                    --disable-triggers \
                    --exit-on-error \
                    dump.pgsql 2>&1 | awk '{print strftime(\"%Y-%m-%d %H:%M:%S\"), \$0; fflush()}' &&
                echo \"> \$(date) - Cleaning up dump file\" &&
                  rm -f dump.pgsql &&
                echo \"> \$(date) - Finished restoring\" &&
                  exit 0"

      - name: Run DBT transformations
        run: >-
          scalingo --region osc-secnum-fr1 --app if-prod-nightly-db run --size XL -- bash -c "
                echo \"> \$(date) - Starting DBT run\" &&
                  ./run_dbt.sh run &&
                echo \"> \$(date) - DBT run completed successfully\" &&
                  exit 0"
